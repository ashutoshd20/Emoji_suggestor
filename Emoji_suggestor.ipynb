{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac379ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import io\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff2adad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>he had to make a home run</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>I am ordering food</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>What is wrong with you</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>I love you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>great job</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            sentence  emoji\n",
       "0             never talk to me again      3\n",
       "1    I am proud of your achievements      2\n",
       "2     It is the worst day in my life      3\n",
       "3                   Miss you so much      0\n",
       "4                       food is life      4\n",
       "..                               ...    ...\n",
       "127        he had to make a home run      1\n",
       "128               I am ordering food      4\n",
       "129           What is wrong with you      3\n",
       "130                       I love you      0\n",
       "131                        great job      2\n",
       "\n",
       "[132 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('train_emoji.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de1a1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n",
      "(132,)\n"
     ]
    }
   ],
   "source": [
    "train_X=train['sentence'].to_numpy()\n",
    "train_Y=train['emoji'].to_numpy()\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f96f4517",
   "metadata": {},
   "outputs": [],
   "source": [
    "value=[]\n",
    "embeddings_index = {}\n",
    "with io.open('glove.6B.50d.txt', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        value.append(values)\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:],dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4087da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " '0.418',\n",
       " '0.24968',\n",
       " '-0.41242',\n",
       " '0.1217',\n",
       " '0.34527',\n",
       " '-0.044457',\n",
       " '-0.49688',\n",
       " '-0.17862',\n",
       " '-0.00066023',\n",
       " '-0.6566',\n",
       " '0.27843',\n",
       " '-0.14767',\n",
       " '-0.55677',\n",
       " '0.14658',\n",
       " '-0.0095095',\n",
       " '0.011658',\n",
       " '0.10204',\n",
       " '-0.12792',\n",
       " '-0.8443',\n",
       " '-0.12181',\n",
       " '-0.016801',\n",
       " '-0.33279',\n",
       " '-0.1552',\n",
       " '-0.23131',\n",
       " '-0.19181',\n",
       " '-1.8823',\n",
       " '-0.76746',\n",
       " '0.099051',\n",
       " '-0.42125',\n",
       " '-0.19526',\n",
       " '4.0071',\n",
       " '-0.18594',\n",
       " '-0.52287',\n",
       " '-0.31681',\n",
       " '0.00059213',\n",
       " '0.0074449',\n",
       " '0.17778',\n",
       " '-0.15897',\n",
       " '0.012041',\n",
       " '-0.054223',\n",
       " '-0.29871',\n",
       " '-0.15749',\n",
       " '-0.34758',\n",
       " '-0.045637',\n",
       " '-0.44251',\n",
       " '0.18785',\n",
       " '0.0027849',\n",
       " '-0.18411',\n",
       " '-0.11514',\n",
       " '-0.78581']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(value))\n",
    "print(len(value[0]))\n",
    "value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4995da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_map={}\n",
    "for i,v in enumerate(value):\n",
    "    a=np.zeros((50))\n",
    "    for j in range(1,51):\n",
    "        a[j-1]=(v[j])\n",
    "    word_to_vec_map[value[i][0]]=np.array(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee987c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index={}\n",
    "index_to_word={}\n",
    "for i,v in enumerate(value):\n",
    "    word_to_index[v[0]]=i\n",
    "    index_to_word[i]=v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "291ec025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of son in the dictionary is 630\n",
      "the 25602th word in the dictionary is crenshaw\n"
     ]
    }
   ],
   "source": [
    "word = \"son\"\n",
    "idx = 25602\n",
    "print(\"the index of\", word, \"in the dictionary is\", word_to_index[word])\n",
    "print(\"the\", str(idx) + \"th word in the dictionary is\", index_to_word[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c03de482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    m = X.shape[0] \n",
    "    X_indices = np.zeros([m,max_len])\n",
    "    for i in range(m): \n",
    "        sentence_words=X[i].lower().split()\n",
    "        j=0\n",
    "        for w in sentence_words:\n",
    "            if w in word_to_index:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "                j =  j+1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3112667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_size = len(word_to_index)+1\n",
    "    for i,key in enumerate(word_to_vec_map.keys()):\n",
    "        any_word=key\n",
    "        break\n",
    "    emb_dim = word_to_vec_map[any_word].shape[0]\n",
    "    emb_matrix =  np.zeros([vocab_size,emb_dim])\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] =  word_to_vec_map[word]\n",
    "    embedding_layer = Embedding(vocab_size, emb_dim ,trainable = False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b55f62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0][1][1] = 0.23682\n",
      "Input_dim 400001\n",
      "Output_dim 50\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "print(\"weights[0][1][1] =\", embedding_layer.get_weights()[0][1][1])\n",
    "print(\"Input_dim\", embedding_layer.input_dim)\n",
    "print(\"Output_dim\",embedding_layer.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d37ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(10,)\n",
    "word_to_vec_map1=word_to_vec_map\n",
    "word_to_index1=word_to_index\n",
    "def Emoji_suggestor(hp):\n",
    "    sentence_indices =Input(shape=input_shape,dtype='int32')\n",
    "    embedding_layer =pretrained_embedding_layer(word_to_vec_map1, word_to_index1)\n",
    "    embeddings =embedding_layer(sentence_indices)   \n",
    "    X = LSTM(units=128,return_sequences = True)(embeddings)\n",
    "    X =Dropout(0.5)(X) \n",
    "    X = LSTM(units=128,return_sequences = False)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(hp.Int('dense1_filter', min_value=5, max_value=30, step=5))(X)\n",
    "    X = Dense(5)(X)\n",
    "    X = Activation('softmax')(X)\n",
    "    model = Model(inputs=sentence_indices,outputs=X)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990af94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2ae5899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project output\\emojisugesstor\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from output\\emojisugesstor\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner_search=RandomSearch(Emoji_suggestor,\n",
    "                          objective='val_accuracy',\n",
    "                          max_trials=5,directory='output',project_name=\"emojisugesstor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "688b76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    a=np.zeros((Y.shape[0],C))\n",
    "    for i, y in enumerate(Y):\n",
    "        a[i][Y[i]]=1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a5e7559",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(train_X, word_to_index, 10)\n",
    "Y_train_oh = convert_to_one_hot(train_Y, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "069d0cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(X_train_indices, Y_train_oh, epochs=50,validation_split=0.1, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c009ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner_search.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43915bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 10, 50)            20000050  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10, 128)           91648     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 25)                3225      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 130       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,226,637\n",
      "Trainable params: 226,587\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75655369",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e626802b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/60\n",
      "8/8 [==============================] - 5s 124ms/step - loss: 0.1691 - accuracy: 0.9492 - val_loss: 1.7186 - val_accuracy: 0.5714\n",
      "Epoch 52/60\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2222 - accuracy: 0.9322 - val_loss: 0.1199 - val_accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0973 - accuracy: 0.9661 - val_loss: 1.3503 - val_accuracy: 0.5714\n",
      "Epoch 54/60\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1097 - accuracy: 0.9492 - val_loss: 0.4371 - val_accuracy: 0.8571\n",
      "Epoch 55/60\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1442 - accuracy: 0.9492 - val_loss: 1.4830 - val_accuracy: 0.5714\n",
      "Epoch 56/60\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1202 - accuracy: 0.9576 - val_loss: 0.4506 - val_accuracy: 0.8571\n",
      "Epoch 57/60\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0688 - accuracy: 0.9746 - val_loss: 0.3974 - val_accuracy: 0.8571\n",
      "Epoch 58/60\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.7857\n",
      "Epoch 59/60\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0319 - accuracy: 0.9831 - val_loss: 0.2333 - val_accuracy: 0.9286\n",
      "Epoch 60/60\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0355 - accuracy: 0.9831 - val_loss: 0.8887 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bfa8972b50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs=60,validation_split=0.1,initial_epoch=50, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acd218c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['💖', '⚽', '😀', '😞', '🍽️']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[emoji.emojize(\":sparkling_heart:\"),emoji.emojize(\":soccer_ball:\"),emoji.emojize(\":grinning_face:\"),emoji.emojize(\":disappointed_face:\"),emoji.emojize(\":fork_and_knife_with_plate:\")]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d511e459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./emogi_suggestor_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./emogi_suggestor_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"./emogi_suggestor_model\"\n",
    "\n",
    "localhost_save_option = tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\")\n",
    "model.save(model_dir, options=localhost_save_option)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586dd55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
